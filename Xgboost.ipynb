{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def create_weekly_features(data):\n",
    "    \"\"\"Create weekly aggregated features for stock price prediction.\"\"\"\n",
    "    df_weekly = data.copy()\n",
    "    df_weekly['Week'] = df_weekly.index.isocalendar().week\n",
    "    df_weekly['Month'] = df_weekly.index.month\n",
    "    df_weekly['Year'] = df_weekly.index.year\n",
    "\n",
    "    # Tính toán các đặc trưng theo tuần\n",
    "    df_weekly = df_weekly.groupby(['Year', 'Week']).agg({\n",
    "        'Adj Close': ['mean', 'std', 'min', 'max', 'last'],\n",
    "        'Week': 'first',\n",
    "        'Month': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    df_weekly.columns = ['Year', 'Week', 'weekly_mean', 'weekly_std', 'weekly_min',\n",
    "                        'weekly_max', 'weekly_last', 'Week_num', 'Month']\n",
    "\n",
    "    # Tạo lag features - tăng lên 28 lags\n",
    "    for i in range(1, 29):  # Tăng số lượng lag features lên 28\n",
    "        df_weekly[f'weekly_mean_lag_{i}'] = df_weekly['weekly_mean'].shift(i)\n",
    "        df_weekly[f'weekly_std_lag_{i}'] = df_weekly['weekly_std'].shift(i)\n",
    "\n",
    "    # Tạo rolling features\n",
    "    windows = [2, 3, 4, 5, 7, 14, 21, 28]  # Thêm các windows mới\n",
    "    for window in windows:\n",
    "        df_weekly[f'rolling_mean_{window}'] = df_weekly['weekly_mean'].shift(1).rolling(window=window).mean()\n",
    "        df_weekly[f'rolling_std_{window}'] = df_weekly['weekly_mean'].shift(1).rolling(window=window).std()\n",
    "\n",
    "    # Tạo rate of change features\n",
    "    for i in range(1, 29):  # Tăng số lượng ROC features lên 28\n",
    "        df_weekly[f'roc_{i}'] = df_weekly['weekly_mean'].pct_change(periods=i) * 100\n",
    "\n",
    "    df_weekly['Month_sin'] = np.sin(2 * np.pi * df_weekly['Month']/12)\n",
    "    df_weekly['Month_cos'] = np.cos(2 * np.pi * df_weekly['Month']/12)\n",
    "\n",
    "    return df_weekly.dropna()\n",
    "\n",
    "def calculate_errors(y_true, y_pred):\n",
    "    \"\"\"Tính toán sai số.\"\"\"\n",
    "    return y_true - y_pred\n",
    "\n",
    "def create_error_features(errors):\n",
    "    \"\"\"Tạo đặc trưng từ sai số.\"\"\"\n",
    "    error_features = pd.DataFrame()\n",
    "\n",
    "    # Tạo lag features cho sai số\n",
    "    for i in range(1, 4):  # Giảm số lượng lag\n",
    "        error_features[f'error_lag_{i}'] = pd.Series(errors).shift(i)\n",
    "\n",
    "    # Tạo rolling features cho sai số\n",
    "    error_features['error_ma_3'] = pd.Series(errors).shift(1).rolling(window=3).mean()\n",
    "    error_features['error_std_3'] = pd.Series(errors).shift(1).rolling(window=3).std()\n",
    "\n",
    "    return error_features.fillna(0)\n",
    "\n",
    "def update_features(current_data, new_prediction):\n",
    "    \"\"\"Cập nhật đặc trưng cho lần dự đoán tiếp theo.\"\"\"\n",
    "    updated_data = current_data.copy()\n",
    "\n",
    "    # Cập nhật lag features\n",
    "    for i in range(28, 1, -1):  # Cập nhật cho 28 lags\n",
    "        updated_data[f'weekly_mean_lag_{i}'] = updated_data[f'weekly_mean_lag_{i-1}'].values[0]\n",
    "    updated_data['weekly_mean_lag_1'] = float(new_prediction)\n",
    "\n",
    "    # Cập nhật các features khác\n",
    "    lag_values = [float(new_prediction)]\n",
    "    for i in range(1, 28):  # Cập nhật cho 28 lags\n",
    "        lag_values.append(float(updated_data[f'weekly_mean_lag_{i}'].values[0]))\n",
    "\n",
    "    # Cập nhật rolling features\n",
    "    windows = [2, 3, 4, 5, 7, 14, 21, 28]  # Cập nhật windows\n",
    "    for window in windows:\n",
    "        if len(lag_values) >= window:\n",
    "            updated_data[f'rolling_mean_{window}'] = float(np.mean(lag_values[:window]))\n",
    "            updated_data[f'rolling_std_{window}'] = float(np.std(lag_values[:window]))\n",
    "\n",
    "    # Cập nhật ROC\n",
    "    for i in range(1, 29):  # Cập nhật cho 28 ROC\n",
    "        if i < len(lag_values):\n",
    "            prev_value = lag_values[i]\n",
    "            if prev_value != 0:\n",
    "                updated_data[f'roc_{i}'] = float(((new_prediction - prev_value) / prev_value) * 100)\n",
    "            else:\n",
    "                updated_data[f'roc_{i}'] = 0.0\n",
    "\n",
    "    return updated_data\n",
    "\n",
    "def predict_with_error_correction(price_model, error_model, scaler, pca, last_week_data,\n",
    "                                last_errors_data, n_weeks=1):\n",
    "    \"\"\"Dự đoán với hiệu chỉnh sai số.\"\"\"\n",
    "    predictions = []\n",
    "    error_corrections = []\n",
    "\n",
    "    current_price_data = last_week_data.copy()\n",
    "    current_error_data = last_errors_data.copy()\n",
    "\n",
    "    for _ in range(n_weeks):\n",
    "        # Dự đoán giá\n",
    "        X_scaled = scaler.transform(current_price_data)\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        price_pred = float(price_model.predict(X_pca)[0])\n",
    "\n",
    "        # Dự đoán sai số\n",
    "        error_pred = float(error_model.predict(current_error_data.values.reshape(1, -1))[0])\n",
    "\n",
    "        # Hiệu chỉnh dự đoán\n",
    "        corrected_pred = price_pred + error_pred\n",
    "        predictions.append(corrected_pred)\n",
    "        error_corrections.append(error_pred)\n",
    "\n",
    "        # Cập nhật dữ liệu\n",
    "        current_price_data = update_features(current_price_data, corrected_pred)\n",
    "        current_error_data = pd.DataFrame([error_pred] + list(current_error_data.iloc[0][:-1])).T\n",
    "        current_error_data.columns = last_errors_data.columns\n",
    "\n",
    "    return predictions, error_corrections\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Tính toán các chỉ số đánh giá.\"\"\"\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # Tính Directional Accuracy\n",
    "    y_true_direction = np.diff(y_true) > 0\n",
    "    y_pred_direction = np.diff(y_pred) > 0\n",
    "    da = np.mean(y_true_direction == y_pred_direction) * 100\n",
    "\n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'DA': da\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    file_path = 'Toyota_Data.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna()\n",
    "    df = df.drop(['High', 'Low', 'Close', 'Open', 'Volume'], axis=1)\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Split data\n",
    "    df_train = df['2004/01/01':'2024/12/31']  # Gộp tất cả dữ liệu\n",
    "\n",
    "    # Create features\n",
    "    features_df = create_weekly_features(df_train)\n",
    "\n",
    "    # Prepare data\n",
    "    X = features_df.drop(['weekly_mean', 'Year', 'Week', 'Month'], axis=1)\n",
    "    y = features_df['weekly_mean']\n",
    "    print(\"Số lượng cột trong X:\", len(X.columns))\n",
    "    # Chia dữ liệu thành train và test\n",
    "    test_size = 24  # 24 tuần cuối làm test\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:]\n",
    "\n",
    "    # Preprocess\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    print(f\"Number of components after PCA: {pca.n_components_}\")\n",
    "\n",
    "    # Train price prediction model\n",
    "    price_model = XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    price_model.fit(X_train_pca, y_train)\n",
    "\n",
    "    # Model 1: Direct prediction on test set\n",
    "    y_pred_test = price_model.predict(X_test_pca)\n",
    "\n",
    "    # Model 2: Sequential prediction starting from train set\n",
    "    sequential_predictions = []\n",
    "    current_data = X_train.iloc[[-1]].copy()  # Bắt đầu từ tuần cuối của tập train\n",
    "\n",
    "    for _ in range(test_size):\n",
    "        print(X.iloc[-1])\n",
    "        # Predict next week\n",
    "        X_scaled = scaler.transform(current_data)\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        pred = float(price_model.predict(X_pca)[0])\n",
    "        sequential_predictions.append(pred)\n",
    "\n",
    "        # Update features for next prediction\n",
    "        current_data = update_features(current_data, pred)\n",
    "\n",
    "    # Calculate metrics for both models\n",
    "    model1_metrics = calculate_metrics(y_test.values, y_pred_test)\n",
    "    model2_metrics = calculate_metrics(y_test.values, sequential_predictions)\n",
    "\n",
    "    print(\"\\nMetrics for Model 1 (Direct Test Prediction):\")\n",
    "    print(f\"MAE: {model1_metrics['MAE']:.2f}\")\n",
    "    print(f\"RMSE: {model1_metrics['RMSE']:.2f}\")\n",
    "    print(f\"DA: {model1_metrics['DA']:.2f}%\")\n",
    "\n",
    "    print(\"\\nMetrics for Model 2 (Sequential Train Prediction):\")\n",
    "    print(f\"MAE: {model2_metrics['MAE']:.2f}\")\n",
    "    print(f\"RMSE: {model2_metrics['RMSE']:.2f}\")\n",
    "    print(f\"DA: {model2_metrics['DA']:.2f}%\")\n",
    "\n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot data\n",
    "    weeks = range(len(y_test))\n",
    "\n",
    "    # Plot actual values\n",
    "    plt.plot(weeks, y_test.values, label=\"Actual Values\", color='blue', linewidth=2)\n",
    "\n",
    "    # Plot Model 1 predictions\n",
    "    plt.plot(weeks, y_pred_test, label=\"Model 1 (Test)\", color='red', linestyle='--')\n",
    "\n",
    "    # Plot Model 2 predictions\n",
    "    plt.plot(weeks, sequential_predictions, label=\"Model 2 (Train)\", color='green', linestyle='--')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Comparison of Two Prediction Models\")\n",
    "    plt.xlabel(\"Week\")\n",
    "    plt.ylabel(\"Price\")\n",
    "\n",
    "    # Add metrics to plot\n",
    "    metrics_text = (\n",
    "        f'Model 1 (Test):\\n'\n",
    "        f'MAE: {model1_metrics[\"MAE\"]:.2f}\\n'\n",
    "        f'RMSE: {model1_metrics[\"RMSE\"]:.2f}\\n'\n",
    "        f'DA: {model1_metrics[\"DA\"]:.2f}%\\n\\n'\n",
    "        f'Model 2 (Train):\\n'\n",
    "        f'MAE: {model2_metrics[\"MAE\"]:.2f}\\n'\n",
    "        f'RMSE: {model2_metrics[\"RMSE\"]:.2f}\\n'\n",
    "        f'DA: {model2_metrics[\"DA\"]:.2f}%'\n",
    "    )\n",
    "\n",
    "    plt.text(0.02, 0.98, metrics_text,\n",
    "             transform=plt.gca().transAxes,\n",
    "             bbox=dict(facecolor='white', alpha=0.8),\n",
    "             verticalalignment='top')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot errors for both models\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Model 1 errors\n",
    "    model1_errors = y_test.values - y_pred_test\n",
    "    plt.plot(weeks, model1_errors, label='Model 1 Errors', color='red')\n",
    "\n",
    "    # Model 2 errors\n",
    "    model2_errors = y_test.values - sequential_predictions\n",
    "    plt.plot(weeks, model2_errors, label='Model 2 Errors', color='green')\n",
    "\n",
    "    plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.title('Prediction Errors for Both Models')\n",
    "    plt.xlabel('Week')\n",
    "    plt.ylabel('Error (Actual - Predicted)')\n",
    "    plt.show()\n",
    "    # Plot feature importance for original features\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Get original feature names\n",
    "    original_feature_names = X.columns.tolist()\n",
    "\n",
    "    # Create a new model to get importance of original features\n",
    "    original_model = XGBRegressor(\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    original_model.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importance\n",
    "    original_importance = original_model.feature_importances_\n",
    "\n",
    "    # Sort features by importance\n",
    "    sorted_idx = np.argsort(original_importance)\n",
    "\n",
    "    # Create a DataFrame for better visualization\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': [original_feature_names[i] for i in sorted_idx],\n",
    "        'Importance': original_importance[sorted_idx]\n",
    "    })\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.barh(range(len(sorted_idx)), original_importance[sorted_idx])\n",
    "    plt.yticks(range(len(sorted_idx)), [original_feature_names[i] for i in sorted_idx])\n",
    "    plt.title('Feature Importance for Stock Price Prediction')\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "\n",
    "    # Add importance values on the bars\n",
    "    for i, v in enumerate(original_importance[sorted_idx]):\n",
    "        plt.text(v, i, f' {v:.4f}', va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print feature importance in a table format\n",
    "    print(\"\\nFeature Importance Table:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Feature':<40} {'Importance':<20}\")\n",
    "    print(\"-\" * 80)\n",
    "    for feature, importance in zip(original_feature_names, original_importance):\n",
    "        print(f\"{feature:<40} {importance:.6f}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Group features by type and calculate average importance\n",
    "    feature_groups = {\n",
    "        'Lag Features': [f for f in original_feature_names if 'lag' in f],\n",
    "        'Rolling Features': [f for f in original_feature_names if 'rolling' in f],\n",
    "        'Rate of Change': [f for f in original_feature_names if 'roc' in f],\n",
    "        'Seasonal Features': [f for f in original_feature_names if 'Month' in f]\n",
    "    }\n",
    "\n",
    "    # Calculate average importance for each group\n",
    "    group_importance = {}\n",
    "    for group_name, features in feature_groups.items():\n",
    "        group_importance[group_name] = np.mean([original_importance[original_feature_names.index(f)] for f in features])\n",
    "\n",
    "    # Plot group importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(range(len(group_importance)), list(group_importance.values()))\n",
    "    plt.yticks(range(len(group_importance)), list(group_importance.keys()))\n",
    "    plt.title('Average Feature Importance by Group')\n",
    "    plt.xlabel('Average Importance Score')\n",
    "    plt.ylabel('Feature Groups')\n",
    "\n",
    "    # Add importance values on the bars\n",
    "    for i, v in enumerate(group_importance.values()):\n",
    "        plt.text(v, i, f' {v:.4f}', va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print group importance in a table format\n",
    "    print(\"\\nGroup Feature Importance:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Group':<20} {'Average Importance':<20}\")\n",
    "    print(\"-\" * 50)\n",
    "    for group, importance in group_importance.items():\n",
    "        print(f\"{group:<20} {importance:.6f}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
